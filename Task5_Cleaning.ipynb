{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e413e86",
   "metadata": {},
   "source": [
    "# Task 5: House Prices Dataset — Data Cleaning (Pandas)\n",
    "\n",
    "**Goal:** Clean the raw dataset using Pandas (missing values, duplicates, datatypes, feature creation) and export a cleaned CSV.\n",
    "\n",
    "**Deliverables:**\n",
    "- Task5_Cleaning.ipynb\n",
    "- cleaned_data.csv\n",
    "- 5–10 markdown notes inside the notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88c25e",
   "metadata": {},
   "source": [
    "## 1) Environment Setup\n",
    "Google Colab is used to ensure an easy, reproducible environment with common data science libraries pre-installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b0d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# If you're using Colab, upload your CSV to the session (Files pane) or mount Google Drive.\n",
    "# Dataset used in this task:\n",
    "file_name = 'Bangalore.csv'\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb86d6",
   "metadata": {},
   "source": [
    "## 2) Dataset Overview\n",
    "We use `.head()` and `.info()` to understand the structure, column types, and whether there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84313ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645133c",
   "metadata": {},
   "source": [
    "## 3) Missing Values Check\n",
    "We identify missing values per column using `isnull().sum()` so we can decide how to clean them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum().sort_values(ascending=False)\n",
    "print(missing.head(20))\n",
    "print('\\nTotal missing values:', int(missing.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf206d7",
   "metadata": {},
   "source": [
    "## 4) Remove Duplicates\n",
    "Duplicate rows can distort results. We drop duplicates and verify the number of rows removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73689f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_rows = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "after_rows = df.shape[0]\n",
    "\n",
    "print('Rows before:', before_rows)\n",
    "print('Rows after :', after_rows)\n",
    "print('Removed    :', before_rows - after_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcf721",
   "metadata": {},
   "source": [
    "## 5) Clean Missing Values\n",
    "Strategy:\n",
    "- Numeric columns → fill using **median** (robust to outliers)\n",
    "- Categorical columns → fill using **mode**\n",
    "- If a column has very high missingness, it may be dropped (not needed here if missing is low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da171b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Fill numeric with median\n",
    "for col in num_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Fill categorical with mode\n",
    "for col in cat_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print('Remaining missing values:', int(df.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2386db",
   "metadata": {},
   "source": [
    "## 6) Datatype Conversion\n",
    "We convert date-like columns to datetime if present. This enables correct time-based calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bed92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any column containing 'date' in its name to datetime\n",
    "for col in df.columns:\n",
    "    if 'date' in col.lower():\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# If conversion creates missing dates (NaT), fill with mode (optional)\n",
    "for col in df.columns:\n",
    "    if pd.api.types.is_datetime64_any_dtype(df[col]) and df[col].isnull().sum() > 0:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print('Datetime columns:', [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c])])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f762ac9",
   "metadata": {},
   "source": [
    "## 7) Feature Engineering (New Column)\n",
    "We create a new column to demonstrate transformation skills. If a price column exists, we create `Price_Band` (Low/Medium/High) using quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_cols = [c for c in df.columns if 'price' in c.lower()]\n",
    "print('Possible price columns:', price_cols)\n",
    "\n",
    "if price_cols:\n",
    "    price_col = price_cols[0]\n",
    "    # Create 3 bands using quantiles\n",
    "    df['Price_Band'] = pd.qcut(df[price_col], q=3, labels=['Low', 'Medium', 'High'])\n",
    "    print(df[['Price_Band', price_col]].head())\n",
    "else:\n",
    "    print('No price column detected. If your dataset has price, rename it to include \"price\" or set price_col manually.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa5bf59",
   "metadata": {},
   "source": [
    "## 8) Final Quality Checks\n",
    "We confirm final shape, missing values, and basic descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final shape:', df.shape)\n",
    "print('Total missing values:', int(df.isnull().sum().sum()))\n",
    "df.describe(include='all').T.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17606db",
   "metadata": {},
   "source": [
    "## 9) Export Cleaned Dataset\n",
    "We save the cleaned dataset as `cleaned_data.csv` and confirm the file is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'cleaned_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print('Saved:', output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e6405",
   "metadata": {},
   "source": [
    "## Outcome\n",
    "This notebook demonstrates how Pandas can replace manual Excel cleaning workflows for large datasets, improving speed and reproducibility."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
